{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Étape 1 : Importation des bibliothèques\n",
        "\n",
        "Importez les bibliothèques nécessaires, y compris les composants de TensorFlow et de Keras. Ces bibliothèques fournissent les fonctions nécessaires pour créer des réseaux LSTM et manipuler les données facilement.\n"
      ],
      "metadata": {
        "id": "6p-yXoed82RZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "y_xQQZEqaNq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Étape 2 : Chargement et préparation des données\n",
        "\n",
        "Chargez le dataset de critiques de films IMDb fourni par Keras. Ce dataset contient des critiques de films prétraitées avec des étiquettes correspondantes (positives ou négatives). Nous limitons le vocabulaire aux 10 000 mots les plus fréquents et ajustons la longueur des séquences à un maximum de 500 pour assurer une taille d'entrée uniforme.\n",
        "\n"
      ],
      "metadata": {
        "id": "z6aDwfA89MzB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huwgZ96-0isC",
        "outputId": "3b553848-7652-4755-db78-fb2d8bafe5ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17464789/17464789 [==============================] - 1s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Load the IMDb dataset\n",
        "(vocab_train, labels_train), (vocab_test, labels_test) = imdb.load_data(num_words=10000)\n",
        "\n",
        "# Padding sequences to ensure uniform input size\n",
        "max_length = 500\n",
        "vocab_train = pad_sequences(vocab_train, maxlen=max_length, padding='post')\n",
        "vocab_test = pad_sequences(vocab_test, maxlen=max_length, padding='post')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Étape 3 : Construction du modèle LSTM\n",
        "\n",
        "Construisez le modèle LSTM en utilisant l'API Sequential. Nous commençons par une couche d'Embedding pour transformer les entiers (indices de mots) en vecteurs denses, ajoutons une couche LSTM avec dropout pour prévenir le surajustement, et utilisons une couche Dense de sortie avec une fonction d'activation sigmoïde pour la classification binaire.\n"
      ],
      "metadata": {
        "id": "icQMWG-t9W46"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=10000, output_dim=128, input_length=max_length))\n",
        "model.add(LSTM(units=50, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FW_5pWOfaZuH",
        "outputId": "ecddf3fd-b433-49f0-87b6-da7fa03a2535"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 500, 128)          1280000   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 50)                35800     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 51        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1315851 (5.02 MB)\n",
            "Trainable params: 1315851 (5.02 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Étape 4 : Entraînement du modèle\n",
        "\n",
        "Entraînez le modèle LSTM sur les données d'entraînement avec une division de validation pour surveiller la performance sur des données non vues. Ici, nous utilisons 5 époques et une taille de lot de 64 pour l'entraînement.\n"
      ],
      "metadata": {
        "id": "rYkP1cY99cxi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(vocab_train, labels_train, epochs=5, batch_size=64, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1QKtTj_1gRa",
        "outputId": "56ae8040-ae56-4d82-aaf5-59e573de19cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "313/313 [==============================] - 526s 2s/step - loss: 0.6925 - accuracy: 0.5024 - val_loss: 0.6905 - val_accuracy: 0.5030\n",
            "Epoch 2/5\n",
            "313/313 [==============================] - 516s 2s/step - loss: 0.6798 - accuracy: 0.5239 - val_loss: 0.6882 - val_accuracy: 0.5124\n",
            "Epoch 3/5\n",
            "313/313 [==============================] - 512s 2s/step - loss: 0.6621 - accuracy: 0.5347 - val_loss: 0.6960 - val_accuracy: 0.5118\n",
            "Epoch 4/5\n",
            "313/313 [==============================] - 511s 2s/step - loss: 0.6490 - accuracy: 0.5396 - val_loss: 0.7153 - val_accuracy: 0.5088\n",
            "Epoch 5/5\n",
            "313/313 [==============================] - 506s 2s/step - loss: 0.6388 - accuracy: 0.5464 - val_loss: 0.7141 - val_accuracy: 0.5242\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Étape 5 : Évaluation du modèle\n",
        "\n",
        "Évaluez le modèle LSTM entraîné sur le jeu de test pour voir comment il performe sur des données non vues. Nous mesurons l'exactitude du modèle, ce qui nous donne une indication de son efficacité à classifier le sentiment des critiques de films.\n"
      ],
      "metadata": {
        "id": "mUPPyv6x9h_s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(vocab_test, labels_test)\n",
        "print(f'Test Accuracy: {accuracy*100:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFVrCy8l1isk",
        "outputId": "50654d1d-1ba2-4bd4-9759-ca3d725dc28a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 102s 131ms/step - loss: 0.7119 - accuracy: 0.5192\n",
            "Test Accuracy: 51.92%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "\n",
        "Ce tutoriel a démontré la configuration de base d'un LSTM pour l'analyse de sentiments sur les critiques de films IMDb. Les LSTM sont puissants pour manipuler des séquences pour des tâches comme l'analyse de sentiments en raison de leur capacité à maintenir des dépendances à long terme dans les données séquentielles. Expérimenter avec différentes configurations et ajuster les paramètres pourrait potentiellement améliorer encore plus la précision de vos modèles.\n",
        "\n"
      ],
      "metadata": {
        "id": "Hsst8TYG9mci"
      }
    }
  ]
}